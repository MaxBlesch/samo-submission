%  LaTeX template for abstract submission for SAMO 2022
% 
% First name and name of the speaker.
\speaker{Philipp}{Eisenhauer}%
%  (put no space here)
% Title of the talk, capitalized.
\title{Structural models for policy-making*
Coping with parametric uncertainty}

% For each author, give the first name, family name, affiliation, and email.
% Ideally, the affiliation and email should fit on a single line.  
% No need to put the full snail mailing address.  
%  One line per author 
\author{Philipp}{Eisenhauer}{Economics, University of Bonn, Germany}{peisenha@uni-bonn.de}
\author{Jano\'s }{Gabler}{Economics, University of Bonn, Germany}{janos.gabler@uni-bonn.de}
\author{Lena}{Janys}{Economics, University of Bonn, Germany}{ljanys@uni-bonn.de}

% Type your abstract here.
\abstract{%Include your abstract here. You can give references  like here \cite{ref1} or \cite{ref2}. 
%Recall that if you need to define your own macros, it is required to include your name in their definitions. \textbf{(1,000 words and 2 pages maximum)}
Economists use highly parameterized structural models to investigate economic mechanisms, predict the impact of proposed policies, and inform optimal policy-making \cite{Wolpin.2013}. These models represent deep structural relationships of theoretical economic models invariant to policy changes \cite{Hood.1953}. The sources of uncertainty in such an analysis are ubiquitous \cite{Saltelli.2020}. For example, all models are misspecified, there are numerical approximation errors in their implementation, and model parameters are uncertain. Therefore, a proper accounting of uncertainty is a prerequisite for using computational models for decision-making in most disciplines \cite{Council.2012,SAPEA.2019}.\\

\noindent Our focus is on parametric uncertainty in structural econometric models that are estimated on observed data. Economists often ignore parametric uncertainty and  conduct an as-if analysis where the point estimates serve as a stand-in for the true model parameters. We then continue to study the implications of our models at the point estimates \cite{Adda.2017,Blundell.2016,Eckstein.2019,Eisenhauer.2015b} and rank competing policy proposals based on the point predictions only \cite{Blundell.2012,Cunha.2010,Gayle.2019,Todd.2006}. In fact, in their handbook article, \cite{Keane.2011d} state that they are unaware of any applied work that reported the distribution of policy predictions due to parametric uncertainty. To the best of our knowledge, this statement remains true more than a decade later. Consequently, economists run the risk of accepting fragile findings as facts, ignoring the trade-off between model complexity and prediction uncertainty, and not framing policy advice as a decision problem under uncertainty.\\

\noindent In this paper, we develop an approach that copes with parametric uncertainty and embeds model-informed policy-making in a decision-theoretic framework. We follow \cite{Manski.2021}'s suggestion and, instead of using the parameter estimates as-if they were true, incorporate uncertainty in the analysis by treating the estimated confidence set as-if it is correct. We use the confidence set to construct an uncertainty set that is anchored in empirical estimates, statistically meaningful, and computationally tractable \cite{Ben-Tal.2013}. Instead of just focusing on the point estimates, we evaluate counterfactual policies based on all parametrizations within the uncertainty set.\\

\noindent We rely on statistical decision theory \cite{Manski.2013} to deal with the uncertainty in counterfactual predictions. This approach promotes a well-reasoned and transparent policy process. Before a decision, it clarifies trade-offs between choices \cite{Gilboa.2018}. Afterward, decision-theoretic principles allow constituents to scrutinize the coherence of choices \cite{Gilboa.2020}, ease the ex-post justification \cite{Berger.2021}, and facilitate the communication of uncertainty \cite{Manski.2019}.\\

\noindent As an example of our generic approach, we analyze the seminal human capital investment model by  \cite{Keane.1997} as a well-known, empirically grounded, and computationally demanding test case. We follow the authors and estimate the model on the National Longitudinal Survey of Youth 1979 (NLSY79) \cite{NLSY.2019} using the original dataset and reproduce all core results. We revisit their predictions for the impact of a tuition subsidy on completed years of schooling. The economics of the model imply that the nonlinear mapping between the model parameters and predictions is truncated at zero. We thus use the Confidence Set (CS) bootstrap \cite{Woutersen.2019} to estimate the confidence set for the counterfactuals. We document considerable uncertainty in the policy predictions and highlight the resulting policy recommendations from different formal rules on decision-making under uncertainty. \\

\noindent Our work extends existing research exploring the sensitivity of implications and predictions to parametric uncertainty in macroeconomics and climate economics. For example, \cite{Harenberg.2019} study uncertainty propagation and sensitivity analysis for a standard real business cycle model. \cite{Cai.2019} examine how uncertainties and risks in economic and climate systems affect the social cost of carbon. However, neither of them estimates their model on data. Instead they rely on expert judgments to inform the degree of parametric uncertainty. They do not investigate the consequences of uncertainty for policy decisions in a decision-theoretic framework.\\

\noindent Our work complements a burgeoning literature on the sensitivity analysis of policy predictions in light of model or moment misspecification. For example, \cite{Andrews.2017} and \cite{Andrews.2020} treat the model specification as given and then analyze the sensitivity of the parameter estimates to misspecification of the moments used for estimation. \cite{Christensen.2019} study global sensitivity of the model predictions to misspecification of the distribution of unobservables. \cite{Jorgensen.2021} provides a local measure for the sensitivity of counterfactuals to model parameters that are fixed before the estimation of the model.\footnote{See for other examples \cite{Armstrong.2021}, \cite{Bonhomme.2020}, \cite{Bugni.2019}, and \cite{Mukhin.2018}.} This literature does not embed the counterfactual predictions in a decision-thoretic setting.\\

%\noindent We structure the remainder of this paper as follows. We first describe the decision-theoretic framework for making model-informed decisions under parametric uncertainty in Section \ref{Framework} using an illustrative example. We then summarize the empirical setting of \cite{Keane.1997} in Section \ref{Setting}, before Section \ref{Results} presents our results before.  We finish in Section \ref{Conclusion} with a brief conclusion and outlook.



	
	
%  If you have references, put them here in a format like below. 
%  This can be obtained using BiBTeX with the bib style plain.bst, uncommenting first the two next lines and replacing them by the generated .bbl file
\newpage
 \bibliographystyle{plain} 
  \bibliography{literature.bib}
% 
%  Note that this bibliography must be placed inside the abstract.
%\begin{thebibliography}{1}

%\bibitem{ref1}
%P. Name.  
%\newblock Paper {T}itle.
%\newblock {\em Journal Title},  X (x): 1--12, Year.

%\bibitem{ref2}
%D.~Name2.
%\newblock {\em Book Title}.
%\newblock Publisher, Year.

%\end{thebibliography}
}  % End of abstract.

